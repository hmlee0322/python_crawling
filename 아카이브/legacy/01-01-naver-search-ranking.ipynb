{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 업무자동화를 위한 파이썬 입문 CAMP #10-01-01\n",
    "\n",
    "\n",
    "> 주제 : 네이버에서 실시간 검색어 순위를 크롤링해서 출력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "\n",
    "```shell\n",
    "$ pip install requests\n",
    "$ pip install beautifulsoup4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  # http request 를 보내고 받기 위해서 사용됩니다.\n",
    "from bs4 import BeautifulSoup  # html 을 parsing 하기 위해서 사용됩니다.\n",
    "\n",
    "\n",
    "# 즉, 저희는 크게 2가지 파이썬 패키지 ( 라이브러리 )를 사용하게 되는데요, \n",
    "#\n",
    "# 1. requests => html request 를 보내서, html response ( html, css, javascript )\n",
    "#                를 받는다.\n",
    "# 2. bs4 ( beautifulsoup4 ) => requests 를 통해서 받은 response 에서 우리가 필요한\n",
    "#                              데이터를 파싱한다.\n",
    "#\n",
    "# 알아두셔야할 점 => 우리가 흔히 크롤링 이라고 부르는 부분은 이렇게 항상 [1. Crawling] + [2. Parsing]이\n",
    "#                합쳐진 거라고 생각하시면 좋을 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"http://www.naver.com/\")\n",
    "assert response.status_code is 200\n",
    "\n",
    "\n",
    "# 위의 `assert response.status_code is 200`의 의미는 네이버 서버를 통해서\n",
    "# response의 status_code 가 200인지 확인해보는 과정입니다. ( 테스트 )\n",
    "#\n",
    "# 각각의 status_code는 고유의 의미를 가지고 있는데, 많이 사용되는 것만 간단하게 소개를 드립니다:\n",
    "# 200 => OK ( 성공 )\n",
    "# 404 => NOT FOUND, 이 경우에는 제대로 크롤링을 하기가 힘들겠죠?\n",
    "#\n",
    "# 각각의 Status Code 들에 대해서는 https://www.w3.org/Protocols/HTTP/HTRESP.html 에서 추가적으로 살펴보실 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dom = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```html\n",
    "...\n",
    "<ol id=\"realrank\">\n",
    "    <li>패스트캠퍼스</li>\n",
    "    <li>업무자동화</li>\n",
    "    <li>업무자동화</li>\n",
    "    ...\n",
    "</ol>\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적으로 bs4와 같은 parser에서 html element 를 선택하기 위한\n",
    "# 다양한 방법이 있지만, 가장 선호되는 방식은 \"css select\" 방식입니다.\n",
    "#\n",
    "# id => \"#\"\n",
    "# class  => \".\"\n",
    "\n",
    "# 예를 들어, 위의 html 코드에서 살펴보면,\n",
    "# \"realrank\"라는 \"id\"를 가진 \"ol\" 태그 > 안에 들어있는 \"li\" 태그를 선택하려면,\n",
    "# \"ol#realrank li\"로 선택을 할 수 있습니다.\n",
    "\n",
    "ranking_elements = dom.select(\"ol#realrank li\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지카바이러스\n",
      "이태원 살인사건\n",
      "꽃보다 청춘\n",
      "엔화환율\n",
      "한일전\n",
      "서유리\n",
      "라오니치\n",
      "카타르 이라크\n",
      "조현병\n",
      "시그널\n"
     ]
    }
   ],
   "source": [
    "for ranking_element in ranking_elements[:-1]:\n",
    "    ranking_title_element = ranking_element.select(\"a\")[0]\n",
    "    print(ranking_title_element.attrs.get('title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> 수고하셨습니다. 감사합니다. - 안수찬 올림."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
